
#  Projet M2 â€” Pipeline ETL DistribuÃ© (DonnÃ©es AÃ©riennes)

**DurÃ©e** : 1 semaine  
**BinÃ´me** : Eya Bensalem & Yasmine  

##  Objectif

Mettre en place un **pipeline Big Data distribuÃ©** pour collecter, traiter et visualiser des **donnÃ©es aÃ©riennes en temps rÃ©el** Ã  partir de lâ€™API *OpenAIP*.

Le pipeline repose sur les technologies suivantes :  
**Apache NiFi â†’ Apache Kafka â†’ Apache Spark â†’ PostgreSQL â†’ Power BI**


##  Architecture globale

![Architecture](architecture.png)

> Ce pipeline rÃ©alise un traitement complet des donnÃ©es aÃ©riennes :  
> - **NiFi** ingÃ¨re les donnÃ©es JSON depuis lâ€™API OpenAIP.  
> - **Kafka** assure la transmission des messages.  
> - **Spark Streaming** lit les flux Kafka, nettoie et normalise les donnÃ©es.  
> - **PostgreSQL** stocke les rÃ©sultats structurÃ©s.  
> - **Power BI** permet la visualisation et lâ€™analyse des indicateurs en temps rÃ©el.


##  Explication des composants

###  **NiFi**
- Interroge lâ€™API:**OpenAIP** toutes les **30 secondes**.  
- Nettoie et reformate les donnÃ©es.  
- Publie les messages JSON vers le Topic **Kafka** (`flights_positions`).  

Flux NiFi :

InvokeHTTP â†’ EvaluateJsonPath â†’ AttributesToJSON â†’ PublishKafkaRecord_2_0


###  **Kafka**
- Topic principal : `flights_positions`
- Sert de **file dâ€™attente distribuÃ©e** entre NiFi et Spark.
- VÃ©rification des messages via **Offset Explorer** (visualisation des partitions et offsets).


### **Apache Spark**

Fichier principal : `stream_flights.py`  

Lecture depuis Kafka, parsing JSON, aplatissement, et Ã©criture dans **PostgreSQL**.

#### SchÃ©ma traitÃ©
- DonnÃ©es sur les **aÃ©roports** (id, nom, pays, coordonnÃ©es, longueur des pistes, altitude, etc.)

/// image des donnÃ©es 
![donnÃ©es_aÃ©roport](donnÃ©es_aÃ©roport.png)

#### Exemple dâ€™exÃ©cution
```bash
spark-submit \
  --packages org.apache.spark:spark-sql-kafka-0-10_2.12:3.5.1,org.postgresql:postgresql:42.6.0 \
  stream_flights.py
````

#### Configuration

le docker_file compose: 
docker-compose-M2DATA.yml 

### **PostgreSQL**

Deux tables principales sont utilisÃ©es :

| Table              | Description                                                         |
| ------------------ | ------------------------------------------------------------------- |
| **airports_clean** | DonnÃ©es nettoyÃ©es sur les aÃ©roports (structure issue du code Spark) |

#### Capture de crÃ©ation des tables


### **Power BI**

La base **PostgreSQL** est connectÃ©e Ã  Power BI pour la visualisation.

#### Visualisations proposÃ©es :

ğŸ“Š Visualisations proposÃ©es

Le tableau de bord Power BI permet dâ€™explorer et analyser les aÃ©roports du monde grÃ¢ce aux donnÃ©es traitÃ©es par le pipeline Big Data.

ğŸŒ Carte mondiale

Affiche tous les aÃ©roports par localisation (lat/lon) pour visualiser leur distribution globale.

ğŸ”¢ Indicateurs clÃ©s

Nombre dâ€™aÃ©roports

Nombre de pays

Altitude moyenne

Longueur moyenne des pistes

ğŸ© RÃ©partition par nombre de pistes

Donut chart montrant la proportion dâ€™aÃ©roports selon leur nombre de pistes.

ğŸ“Š Nombre dâ€™aÃ©roports par pays

Classement des pays selon leur quantitÃ© dâ€™aÃ©roports.

ğŸ›« Top 10 plus longues pistes

Graphique en bulles affichant les aÃ©roports avec les plus grandes pistes (capacitÃ© longs courriers/cargos).

ğŸ“‹ Tableau dÃ©taillÃ©

Liste interactive des aÃ©roports (pays, nom, altitude, longueur piste, nb pistes).

ğŸ›ï¸ Filtre par pays

Permet de filtrer toutes les visualisations par pays.

## Exemple de donnÃ©es JSON

Message envoyÃ© par NiFi dans le topic Kafka :

image : kafka_output.JPG

##  Lancement global du pipeline

### 1ï¸âƒ£ DÃ©marrage des conteneurs

```bash
docker compose -f docker-compose-M2DATA.yml up -d
```

### 2ï¸âƒ£ NiFi â†’ Kafka

Configurer le flux NiFi (`InvokeHTTP â†’ EvaluateJsonPath â†’ AttributesToJSON â†’ PublishKafkaRecord_2_0`).

image de configuration : 

![paramÃ¨tres_kafka](nifitopic.JPG)
![pipeline_nifi](Nifimarche.JPG)


### 3ï¸âƒ£ VÃ©rification Kafka

```bash
docker exec -it kafka kafka-topics.sh --bootstrap-server kafka:9092 --list
```

```bash
docker exec -it kafka kafka-console-consumer.sh --bootstrap-serv
er kafka:9092 --topic flights_positions --from-beginning --max-messages 1
```

ou via **Offset Explorer**.

### 4ï¸âƒ£ Spark Streaming

```bash
docker exec -it spark-master /opt/spark/bin/spark-submit --maste
r spark://spark-master:7077 --packages org.apache.spark:spark-sql-kafka-0-10_2.12:3.5.1,org.postgresql:postgresql:42.6.0 /tmp/stream
_flights.py
```

### 5ï¸âƒ£ Power BI

Connecter PostgreSQL et actualiser les visuels en temps rÃ©el.


## ğŸ“ Structure du dÃ©pÃ´t

â”œâ”€â”€ architecture.png           # SchÃ©ma du pipeline
â”œâ”€â”€ docker-compose-M2DATA.yml  # Environnement Docker
â”œâ”€â”€ stream_flights.py          # Code Spark Streaming
â”œâ”€â”€ bi_dashboard.pbix          # partie power BI 
â”œâ”€â”€ validation_template.xml    # Template NiFi (export)
â”œâ”€â”€ README.md                  # Documentation principale
â””â”€â”€ DonnÃ©es DistribuÃ©es.pptx   # PrÃ©sentation PowerPoint
