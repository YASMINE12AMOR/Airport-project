#  Projet M2 â€” Pipeline ETL DistribuÃ© (DonnÃ©es AÃ©riennes)

**DurÃ©e** : 1 semaine  
**BinÃ´me** : Eya Bensalem & Yasmine  

##  Objectif

Mettre en place un **pipeline Big Data distribuÃ©** pour collecter, traiter et visualiser des **donnÃ©es aÃ©riennes en temps rÃ©el** Ã  partir de lâ€™API *OpenAIP*.

Le pipeline repose sur les technologies suivantes :  
**Apache NiFi â†’ Apache Kafka â†’ Apache Spark â†’ PostgreSQL â†’ Power BI**


##  Architecture globale

![Architecture](images/architecture.png)

> Ce pipeline rÃ©alise un traitement complet des donnÃ©es aÃ©riennes :  
> - **NiFi** ingÃ¨re les donnÃ©es JSON depuis lâ€™API OpenAIP.  
> - **Kafka** assure la transmission des messages.  
> - **Spark Streaming** lit les flux Kafka, nettoie et normalise les donnÃ©es.  
> - **PostgreSQL** stocke les rÃ©sultats structurÃ©s.  
> - **Power BI** permet la visualisation et lâ€™analyse des indicateurs en temps rÃ©el.


##  Explication des composants

###  **NiFi**
- Interroge lâ€™API:**OpenAIP** toutes les **30 secondes**.  
- Nettoie et reformate les donnÃ©es.  
- Publie les messages JSON vers le Topic **Kafka** (`flights_positions`).  

Flux NiFi :

InvokeHTTP â†’ EvaluateJsonPath â†’ AttributesToJSON â†’ PublishKafkaRecord_2_0


###  **Kafka**
- Topic principal : `flights_positions`
- Sert de **file dâ€™attente distribuÃ©e** entre NiFi et Spark.
- VÃ©rification des messages via **Offset Explorer** (visualisation des partitions et offsets).


### **Apache Spark**

Fichier principal : `stream_flights.py`  

Lecture depuis Kafka, parsing JSON, aplatissement, et Ã©criture dans **PostgreSQL**.

#### DonnÃ©es traitÃ©
- DonnÃ©es sur les **aÃ©roports** (id, nom, pays, coordonnÃ©es, longueur des pistes, altitude, etc.)
 
![donnÃ©es_aÃ©roport](images/Data_airport.png)


### **PostgreSQL**

La table crÃ©e :

| Table              | Description                                                         |
| ------------------ | ------------------------------------------------------------------- |
| **airports_clean** | DonnÃ©es nettoyÃ©es sur les aÃ©roports (structure issue du code Spark) |



### **Power BI**
Le tableau de bord Power BI permet dâ€™explorer et analyser les aÃ©roports du monde grÃ¢ce aux donnÃ©es traitÃ©es par le pipeline Big Data.

La base **PostgreSQL** est connectÃ©e Ã  Power BI pour la visualisation.

#### Visualisations :

ğŸŒ Carte mondiale

Affiche tous les aÃ©roports par localisation (lat/lon) pour visualiser leur distribution globale.

![donnÃ©es_aÃ©roport](images/images_powerbi1.png)


ğŸ”¢ Indicateurs clÃ©s

Nombre dâ€™aÃ©roports

Nombre de pays

Altitude moyenne

Longueur moyenne des pistes

ğŸ© RÃ©partition par nombre de pistes

Donut chart montrant la proportion dâ€™aÃ©roports selon leur nombre de pistes.

ğŸ“Š Nombre dâ€™aÃ©roports par pays

Classement des pays selon leur quantitÃ© dâ€™aÃ©roports.

ğŸ›« Top 10 plus longues pistes

Graphique en bulles affichant les aÃ©roports avec les plus grandes pistes (capacitÃ© longs courriers/cargos).

ğŸ“‹ Tableau dÃ©taillÃ©

Liste interactive des aÃ©roports (pays, nom, altitude, longueur piste, nb pistes).

ğŸ›ï¸ Filtre par pays

Permet de filtrer toutes les visualisations par pays.

##  Lancement global du pipeline

### 1ï¸âƒ£ DÃ©marrage des conteneurs

```bash
docker compose -f docker-compose-M2DATA.yml up -d
```

### 2ï¸âƒ£ NiFi â†’ Kafka

Configurer le flux NiFi (`InvokeHTTP â†’ EvaluateJsonPath â†’ AttributesToJSON â†’ PublishKafkaRecord_2_0`).

#### Processeurs Nifi :
![pipeline_nifi](images/Nifimarche.JPG)

#### Configuration du processeur Kafka : 
![paramÃ¨tres_kafka](images/nifitopic.JPG)

### 3ï¸âƒ£ VÃ©rification Kafka

```bash
docker exec -it kafka kafka-topics.sh --bootstrap-server kafka:9092 --list
```

```bash
docker exec -it kafka kafka-console-consumer.sh --bootstrap-serv
er kafka:9092 --topic flights_positions --from-beginning --max-messages 1
```
#### Message envoyÃ© par NiFi Ã  Kafka  :

![donnÃ©es_aÃ©roport](images/kafka_output.JPG)

### 4ï¸âƒ£ Spark Streaming

```bash
docker exec -it spark-master /opt/spark/bin/spark-submit --master spark://spark-master:7077 --packages org.apache.spark:spark-sql-kafka-0-10_2.12:3.5.1,org.postgresql:postgresql:42.6.0 /tmp/stream_flights.py
```

### 5ï¸âƒ£ Power BI

Connecter PostgreSQL et actualiser les visuels en temps rÃ©el.



## ğŸ“‚ Structure du projet

| Fichier / Dossier | Description |
|-------------------|-------------|
| `docker-compose-M2DATA.yml` | Configuration Docker de lâ€™environnement Big Data |
| `Scripts/stream_flights.py` | Script Spark Streaming pour ingestion & traitement |
| `Power BI/bi_dashboard.pbix` | Dashboard Power BI d'analyse |
| `Nifi/validation_template.xml` | Flow NiFi exportÃ© pour automatisation |
| `PrÃ©sentation/DonnÃ©es DistribuÃ©es.pptx` | Support de prÃ©sentation |
| `PrÃ©sentation/Rapport_Donnees_Distribuees.docx` | Rapport |

